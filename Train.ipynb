{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58202842-c8d1-4435-9d6d-93b3fc91f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d729fc8-5b7f-4b9c-8750-7867a8758670",
   "metadata": {},
   "source": [
    "–ü–æ–º–µ–Ω—è–µ–º –º–µ—Å—Ç–∞–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–æ–∫ test,val –º–µ—Å—Ç–∞–º–∏. –°–¥–µ–ª–∞–µ–º —ç—Ç–æ —Ä–∞–¥–∏ —É–¥–æ–±—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –°–∞–º–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∏–∫–∞–∫ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è, –º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da2f00c-e8cf-452b-8ea8-037c5ca8aa0f",
   "metadata": {},
   "source": [
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2bdfdf-85cd-4b57-9d18-256efb31d4c6",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –ø–∞–π–ø–ª–∞–π–Ω –ø–æ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–º –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–∑ —Å–µ–º–µ–π—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d0715cd-1f8f-4ff5-80e9-76a918ac7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from ultralytics import YOLO  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É ultralytics\n",
    "\n",
    "def model_cv(model_name, **kwargs):\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–º–µ–Ω–∏\n",
    "    if model_name == 'nano':\n",
    "        model = YOLO('/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M3/yolo11n-cls.pt')\n",
    "    elif model_name == 'small':\n",
    "        model = YOLO('/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M3/yolo11s-cls.pt')\n",
    "    elif model_name == 'mean':\n",
    "        model = YOLO('/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M3/yolo11m-cls.pt')\n",
    "    else:\n",
    "        raise ValueError(\"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏. –í—ã–±–µ—Ä–∏—Ç–µ 'nano', 'small' –∏–ª–∏ 'mean'.\")\n",
    "\n",
    "    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –∏ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    res = model.train(data='/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/', **kwargs)\n",
    "\n",
    "    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ\n",
    "    total_training_time = time.time() - start_time\n",
    "    training_time_per_epoch_sec = total_training_time / kwargs.get('epochs', 1)  # –î–µ–ª–∏–º –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "    training_time_min = total_training_time / 60  # –í—Ä–µ–º—è –≤ –º–∏–Ω—É—Ç–∞—Ö\n",
    "\n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "    results = model.val()\n",
    "    #–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_prob = []\n",
    "    for dirpath, dirnames, filenames in os.walk('/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/test'):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            y_true.append(list(map(lambda x: int(x), file_path.split('/')[7].split('-')))[1])\n",
    "            result = model.predict(file_path)\n",
    "            for r in result:\n",
    "                a = r.probs.top1.numpy()\n",
    "                b = r.probs.data.numpy()\n",
    "                y_pred_prob.append(b)\n",
    "                y_pred.append(a)\n",
    "        \n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred_prob = np.array(y_pred_prob)\n",
    "        print('y_pred_prob', y_pred_prob)\n",
    "\n",
    "        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_prob, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        print(f\"ROC AUC: {roc_auc:.3f}\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"F1 Score (macro): {f1:.3f}\")\n",
    "        \n",
    "        print(f\"–í—Ä–µ–º—è –Ω–∞ –æ–¥–Ω—É —ç–ø–æ—Ö—É (—Å–µ–∫.): {training_time_per_epoch_sec:.3f}\")\n",
    "        print(f\"–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω.): {training_time_min:.3f}\")\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        results_filename = f\"model_results_{timestamp}.json\"\n",
    "\n",
    "        results_data = {\n",
    "            'roc_auc': roc_auc,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'training_time_per_epoch_sec': training_time_per_epoch_sec,\n",
    "            'training_time_min': training_time_min,\n",
    "            'timestamp': timestamp,\n",
    "            'model_name': model_name,\n",
    "            'val_results': results,\n",
    "            'train_results': res,\n",
    "        }\n",
    "\n",
    "        with open(results_filename, 'w') as f:\n",
    "            json.dump(results_data, f)\n",
    "\n",
    "        return [model, results, results_data]\n",
    "    \n",
    "    else:\n",
    "        print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c78b4-c3c7-4bd8-9729-3a653b1bed4f",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –æ—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78e930e9-323a-4428-9c78-acf4ccc90ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.70 üöÄ Python-3.10.16 torch-2.6.0+cu124 CPU (13th Gen Intel Core(TM) i5-13400)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M3/yolo11n-cls.pt, data=/home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/, epochs=1, time=0.004166666666666667, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=True, device=cpu, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=41, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.1, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/train... found 23004 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/val... found 1000 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/test... found 2000 images in 1000 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=1000\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1   1611240  ultralytics.nn.modules.head.Classify         [256, 1000]                   \n",
      "YOLO11n-cls summary: 151 layers, 2,812,104 parameters, 2,812,104 gradients, 4.3 GFLOPs\n",
      "Transferred 236/236 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/train... 23004 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/val... 1000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=1e-05, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
      "Starting training for 0.004166666666666667 hours...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        1/1         0G      8.528         16        224:   4%|‚ñé         | 53/1438 [00:15<06:39,  3.46it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:16<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.002      0.007\n",
      "\n",
      "1 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from runs/classify/train/weights/last.pt, 5.8MB\n",
      "Optimizer stripped from runs/classify/train/weights/best.pt, 5.8MB\n",
      "\n",
      "Validating runs/classify/train/weights/best.pt...\n",
      "Ultralytics 8.3.70 üöÄ Python-3.10.16 torch-2.6.0+cu124 CPU (13th Gen Intel Core(TM) i5-13400)\n",
      "YOLO11n-cls summary (fused): 112 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/train... found 23004 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/val... found 1000 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/test... found 2000 images in 1000 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:14<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.002      0.008\n",
      "Speed: 0.0ms preprocess, 3.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
      "Ultralytics 8.3.70 üöÄ Python-3.10.16 torch-2.6.0+cu124 CPU (13th Gen Intel Core(TM) i5-13400)\n",
      "YOLO11n-cls summary (fused): 112 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/train... found 23004 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/val... found 1000 images in 1000 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/test... found 2000 images in 1000 classes ‚úÖ \n",
      "WARNING ‚ö†Ô∏è Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/c4/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/C4_M2/preprocessed_images/val... 1000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| \u001b[0m\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:17<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.002      0.008\n",
      "Speed: 0.0ms preprocess, 3.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
      "y_pred_prob []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnano\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m41\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m240\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[99], line 52\u001b[0m, in \u001b[0;36mmodel_cv\u001b[0;34m(model_name, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred_prob\u001b[39m\u001b[38;5;124m'\u001b[39m, y_pred_prob)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m     54\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:619\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03mfrom prediction scores.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;124;03marray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    618\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 619\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m y_score \u001b[38;5;241m=\u001b[39m check_array(y_score, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    623\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    624\u001b[0m ):\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/sklearn/utils/validation.py:1130\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1131\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1132\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1133\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m   1134\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1137\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "res = model_cv('nano', \n",
    "            imgsz=224, epochs=1,\n",
    "            device='cpu', seed=41,\n",
    "         hsv_v = 0.1, cache = True, exist_ok=True, time=1/240\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4acb5-7be2-44d2-8dd0-6572310d7fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
